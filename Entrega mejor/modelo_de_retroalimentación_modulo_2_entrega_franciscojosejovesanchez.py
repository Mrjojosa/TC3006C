# -*- coding: utf-8 -*-
"""Modelo_de_retroalimentación_Modulo_2_Entrega_FranciscoJoseJoveSanchez.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V4NEOwHLt-sDB4_WF1lokCo0zWl5dav3
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/drive")
!pwd # Print working directory

# %cd "/content/drive/MyDrive/ITA/linear reg/nuevo/Entregas/Momento de retroalimentación"
!ls # List files located in defined folder

#Importar librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime as dt
import math

#Leer csv, específicamente el primer año de datos
ds = pd.read_csv('cereal.csv')

#Obtenemos un dataframe para obtener la correlación para saber cuales son los features más impactantes para saber el rating de un cereal
df = pd.DataFrame(ds)
df2 = df[['calories','protein','fat','sodium','fiber','carbo','sugars','potass','vitamins','shelf','weight','cups','cups','rating']].copy()
#Observamos que estos son el azucar, las calorías y la fibra
#Entre más azucar y carbohidratos y menos fibra tenga un cereal, mayor será su rating

corrM = df2.corr()
corrM.style.background_gradient (cmap = 'coolwarm')

dfsr = df[['sugars','rating']].copy()
dfcr = df[['calories','rating']].copy()
dffr = df[['fiber','rating']].copy()

#Tabla y gráfica
print(corrM)

# Entrena el modelo
#w, b = train(df['sugars'], df['fat'], w=0.0, b=0.0, alpha=0.001, epochs=80)

#Graficar los epochs o iteraciones de conforme se van entrenando
#epoch_plots = [1, 2, 4, 8, 16, 32, 64, epochs+1]
#for epoch_plt in epoch_plots:
#  w, b = train_and_plot(df['sugars'], df['fat'], 0.0, 0.0, 0.001, epoch_plt, int(max(df['sugars'])))

#Reporte
#En esta regresión lineal se puede observar que comienza con un costo muy bajo y realmente no puede reducirse mucho por eso mismo
#Visualizando las graficas de los datos puedo ver que talvez con un modelo de mayor grado podría reducirse incluso más, pero creo que es mejor mantenerlo en el menor grado posible y mantener un tanto menos entrenado
#Dicjo esto creo que mantenerse con el modelo de los primeros epochs sería mejor, probabablemente con cualquiera anterior al 15 a excepción de los primeros 3.

#Azucares
plt.scatter(ds['sugars'], ds['rating'], marker='o', c='b')

#Calorias
plt.scatter(ds['calories'], ds['rating'], marker='o', c='b')

#Fibra
plt.scatter(ds['fiber'], ds['rating'], marker='o', c='b')

#Función de descenso gradual que va actualizando los valores de w y b
def update_w_and_b(X, y, w, b, alpha):
  '''Update parameters w and b during 1 epoch'''
  dl_dw = 0.0
  dl_db = 0.0
  N = len(X)
  for i in range(N):
    dl_dw += -2*X[i]*(y[i] - (w*X[i] + b))
    dl_db += -2*(y[i] - (w*X[i] + b))
  #Actualiza w y b
  w = w - (1/float(N))*dl_dw*alpha
  b = b - (1/float(N))*dl_db*alpha
  return w, b

def train(X, y, w, b, alpha, epochs):
  '''Loops over multiple epochs and prints progress'''
  print('Training progress:')
  for e in range(epochs):
    w, b = update_w_and_b(X, y, w, b, alpha)
  # log the progress
    if e % 5 == 0:
      avg_loss_ = avg_loss(X, y, w, b)
      # print("epoch: {} | loss: {}".format(e, avg_loss_))
      print("Epoch {} | Loss: {} | w:{}, b:{}".format(e, avg_loss_, round(w, 4), round(b, 4)))
  return w, b

def train_and_plot(X, y, w, b, alpha, epochs, x_max_plot):
  '''Loops over multiple epochs and plot graphs showing progress'''
  for e in range(epochs):
    w, b = update_w_and_b(X, y, w, b, alpha)
    if e == epochs-1:
      avg_loss_ = avg_loss(X, y, w, b)
      x_list = np.array(range(0,x_max_plot))
      y_list = (x_list * w) + b
      plt.scatter(x=X, y=y)
      plt.plot(y_list, c='r')
      plt.title("Epoch {} | Loss: {} | w:{}, b:{}".format(e, round(avg_loss_,2), round(w, 4), round(b, 4)))
      plt.show()
  return w, b

#Función de costo
def avg_loss(X, y, w, b):
  '''Calculates the MSE'''
  N = len(X)
  total_error = 0.0
  for i in range(N):
    total_error += (y[i] - (w*X[i] + b))**2
  return total_error / float(N)

def predict(x, w, b):
  return w*x + b

w = 0.0
b = 0.0
alpha = 0.01
epochs = 80

# Entrena el modelos
ws, bs = train(df['sugars'], df['rating'], w=0.0, b=0.0, alpha=0.01, epochs=80)
wc, bc = train(df['calories'], df['rating'], w=0.0, b=0.0, alpha=0.01, epochs=80)
wf, bf = train(df['fiber'], df['rating'], w=0.0, b=0.0, alpha=0.01, epochs=80)

#Graficar los epochs o iteraciones de conforme se van entrenando
epoch_plots = [1, 2, 4, 8, 16, 32, 64, epochs+1]
for epoch_plt in epoch_plots:
  ws, bs = train_and_plot(df['sugars'], df['rating'], 0.0, 0.0, 0.01, epoch_plt, int(max(df['sugars'])))
for epoch_plt in epoch_plots:
  wc, bc = train_and_plot(df['calories'], df['rating'], 0.0, 0.0, 0.01, epoch_plt, int(max(df['calories'])))
for epoch_plt in epoch_plots:
  wf, bf = train_and_plot(df['fiber'], df['rating'], 0.0, 0.0, 0.01, epoch_plt, int(max(df['fiber'])))

#Reporte
#En estas regresiones lineales se puede observar que todas comienzan con un costo alto, en el caso de el azúcar y la fibra se puede observar facilmente como decrementa la perdida, pero el de calorías aumenta de gran manera.
#Visualizando las graficas de los datos puedo ver que talvez con un modelo polinomial de mayor grado podría ayudar a reducir la cantidad de perdida, pero creo que es mejor mantenerlo en el menor grado posible y mantener un tanto menos entrenado
#Dicho esto creo que el de la fibra podría quedarse así, incluso el del azucar si no requieres de mucha precisión, pero es un hecho que el de las calorías necesita cambiar.